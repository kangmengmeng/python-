{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.7\"\n",
    "# spark = SparkSession.builder.\\\n",
    "#         config('spark.executor.memory', '6g').\\\n",
    "#         config('spark.executor.cores', '8').\\\n",
    "#         config('spark.driver.memory','6g').\\\n",
    "#         config('spark.executor.instances', '30').\\\n",
    "#         appName('test').\\\n",
    "#         enableHiveSupport().getOrCreate()\n",
    "spark = SparkSession.builder.\\\n",
    "        config('spark.executor.memory', '12g').\\\n",
    "        config('spark.executor.cores', '8').\\\n",
    "        config('spark.driver.memory','12g').\\\n",
    "        config('spark.executor.instances', '30').\\\n",
    "        appName('test').\\\n",
    "        enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.sql('select * from tmp.tmp_kmm_driver_8_27_train_2')\n",
    "train_data = train_data.toPandas()\n",
    "print(\"train_data.shape\",train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = spark.sql('select * from tmp.tmp_kmm_driver_8_26_test_1')\n",
    "test_data = test_data.toPandas()\n",
    "print(\"train_data.shape\",test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.fillna(0)\n",
    "test_data=test_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data = spark.sql('select * from tmp.tmp_kmm_test3')\n",
    "# val_data = val_data.toPandas()\n",
    "# print(\"val_data.shape\",val_data.shape)\n",
    "\n",
    "val_data = spark.sql('select * from \\\n",
    "(select * ,row_number()over(ORDER BY user_guid) as guid from tmp.tmp_kmm_driver_test_826_4 where age between 20 and 50) t1 \\\n",
    "where t1.guid >60000000 and t1.guid <= 70000000  ')\n",
    "# where t1.guid >30000000 and t1.guid <= 40000000  ')\n",
    "# where t1.guid >40000000 and t1.guid <= 50000000  ')\n",
    "# where t1.guid >50000000 and t1.guid <= 60000000  ')\n",
    "\n",
    "\n",
    "val_data = val_data.toPandas()\n",
    "print(\"val_data.shape\",val_data.shape)\n",
    "val_data=val_data.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data1 = pd.DataFrame(val_data, columns=['age','sum_cal', 'sum_ride_time', 'sum_ride_number', 'sum_credit_score',\n",
    "                                           'is_ride_card', 'consume_card_cnt', 'ev_consume_card_cnt', 'purchase_cnt',\n",
    "                                           'ev_all_total_cnt', 'total_card_money', 'total_cnt', 'click'\n",
    "                        ,'type1','type2','type3','type4','type5','type6','type7','type8','type9','type10','type11',\n",
    "                                            'type12','type13','type14','type15','type16','type17','type18','type19',\n",
    "#                                             'city1', 'city2', 'city3', 'city4','city5', 'city6', 'city7','city8', 'city9'\n",
    "#                                             ,'city10', 'city11', 'city12','city13','city14','city15','city16','city17','city18'\n",
    "#                                               ,'time1','time2','time3','time4'\n",
    "                                               ])\n",
    "val_data1['total_card_money']=val_data1['total_card_money'].astype('float')\n",
    "\n",
    "print(val_data1.shape)\n",
    "val_data1.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_data = pd.DataFrame(train_data, columns=['age','sum_cal', 'sum_ride_time', 'sum_ride_number', 'sum_credit_score',\n",
    "                                           'is_ride_card', 'consume_card_cnt', 'ev_consume_card_cnt', 'purchase_cnt',\n",
    "                                           'ev_all_total_cnt', 'total_card_money', 'total_cnt', 'click'\n",
    "                        ,'type1','type2','type3','type4','type5','type6','type7','type8','type9','type10','type11',\n",
    "                                            'type12','type13','type14','type15','type16','type17','type18','type19',\n",
    "#                                             'city1', 'city2', 'city3', 'city4','city5', 'city6', 'city7','city8', 'city9'\n",
    "#                                             ,'city10', 'city11', 'city12','city13','city14','city15','city16','city17','city18'\n",
    "#                                               ,'time1','time2','time3','time4'\n",
    "                                               ])\n",
    "# ,'type1','type2','type3','type4','type5','type6','type7','type8','type9','type10','type11','type12','type13',\n",
    "#                        'type14','type15','type16','type17','type18','type19'\n",
    "#  ,'city1', 'city2', 'city3', 'city4','city5', 'city6', 'city7','city8', 'city9'\n",
    "#   ,'city10', 'city11', 'city12','city13','city14','city15','city16','city17','city18'\n",
    "#                                  ,'time1','time2','time3','time4'\n",
    "train1_data['total_card_money']=train1_data['total_card_money'].astype('float')\n",
    "test1_data = pd.DataFrame(test_data, columns=['age', 'sum_cal', 'sum_ride_time', 'sum_ride_number', 'sum_credit_score',\n",
    "                                           'is_ride_card', 'consume_card_cnt', 'ev_consume_card_cnt', 'purchase_cnt',\n",
    "                                           'ev_all_total_cnt', 'total_card_money', 'total_cnt', 'click'\n",
    "                ,'type1','type2','type3','type4','type5','type6','type7','type8','type9','type10','type11',\n",
    "                                            'type12','type13','type14','type15','type16','type17','type18','type19',\n",
    "#                                             'city1', 'city2', 'city3', 'city4','city5', 'city6', 'city7','city8', 'city9'\n",
    "#                                             ,'city10', 'city11', 'city12','city13','city14','city15','city16','city17','city18'\n",
    "#                                              ,'time1','time2','time3','time4'  \n",
    "                                             ])\n",
    "test1_data['total_card_money']=test1_data['total_card_money'].astype('float')\n",
    "\n",
    "train_data_y = pd.DataFrame(train_data, columns=['lable'])\n",
    "test_data_y = pd.DataFrame(test_data, columns=['lable'])\n",
    "print(train1_data.shape)\n",
    "print(test1_data.shape)\n",
    "print(train_data_y.shape)\n",
    "print(test_data_y.shape)\n",
    "train1_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"---------begin---------\")\n",
    "# model = LogisticRegression()\n",
    "model=XGBClassifier(n_jobs=8,seed=2019,max_depth=3)\n",
    "model.fit(train1_data, train_data_y)\n",
    "# lr_model.fit(train2, train_data_y)\n",
    "\n",
    "print(\"---------train over---------\")\n",
    "# print(\"w: \", model.coef_)\n",
    "# print(\"b: \", model.intercept_)\n",
    "precision = model.predict(test1_data) \n",
    "pro = model.predict_proba(test1_data)\n",
    "target = np.array(test_data_y)\n",
    "\n",
    "print('精确率:{}'.format(precision_score(target,precision )))\n",
    "print('准确率:{}'.format(accuracy_score(target,precision )))\n",
    "print('召回率:{}'.format(recall_score(target,precision )))\n",
    "print('f1:{}'.format(f1_score(target, precision)))\n",
    "print('auc:{}'.format(roc_auc_score(target, pro[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(\n",
    "[pd.DataFrame(test_data, columns=['user_guid']),pd.DataFrame(pro, columns=['预测为0的概率', '预测为1的概率'])], axis=1)\n",
    "result1 = result[(result['预测为1的概率'] >= 0.9)]\n",
    "result1.shape\n",
    "# result1.to_csv(r'result.csv', index=True, header=True )\n",
    "#  pd.to_csv(outputfile, mode='a', index=False, header=False)　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def sta(res_0, a, b):\n",
    "    q1 = res_0[(res_0['预测为1的概率'] >= a) & (res_0['预测为1的概率'] < b)]\n",
    "    mat_0 = confusion_matrix(q1['label'], q1['预测结果'], labels=[1, 0])\n",
    "\n",
    "    new = pd.DataFrame(mat_0.reshape(1, 4), columns=['预测转化_实际转化', '预测未转化_实际转化', '预测转化_实际未转化', '预测未转化_实际未转化'],\n",
    "                       index=['预测概率{0}-{1}'.format(a, b)])\n",
    "    new['准确率'] = metrics.accuracy_score(q1['label'], q1['预测结果'])\n",
    "    metrics.accuracy_score(q1['label'], q1['预测结果'])\n",
    "    return new\n",
    "\n",
    "res_3 = pd.concat(\n",
    "        [pd.DataFrame(target, columns=['label']), pd.DataFrame(precision, columns=['预测结果']), pd.DataFrame(pro, columns=['预测为0的概率', '预测为1的概率'])], axis=1)\n",
    "\n",
    "df3 = sta(res_3, 0.96, 1)\n",
    "for a, b in [[0.94, 0.96],[0.90, 0.94],[0.85, 0.9],[0.8, 0.85], [0.7, 0.8], [0.6, 0.7], [0.5, 0.6], [0.4, 0.5], [0.3, 0.4], [0.2, 0.3], [0.1, 0.2], [0, 0.1]]:\n",
    "    df_new = pd.concat([df3, sta(res_3, a, b)])\n",
    "    df3 = df_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(target ,precision, labels=[1, 0])\n",
    "pd.DataFrame(mat, columns=['预测转化', '预测未转化'], index=['实际转化', '实际未转化'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pro = model.predict_proba(val_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(\n",
    "[pd.DataFrame(val_data, columns=['user_guid']),pd.DataFrame(val_pro, columns=['预测为0的概率', '预测为1的概率'])], axis=1)\n",
    "result1 = result[(result['预测为1的概率'] >= 0.96)]\n",
    "result1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv(r'result1.csv',mode='a', index=True, header=True )  #,mode='a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result[(result['预测为1的概率'] >= 0.94)& (result['预测为1的概率'] <0.96)]\n",
    "result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv(r'result2.csv', mode='a',index=True, header=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv(r'result.csv', index=True, header=True )\n",
    "#  pd.to_csv(outputfile, mode='a', index=False, header=False)　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(\n",
    "[pd.DataFrame(val_data, columns=['user_guid','age']),pd.DataFrame(val_pro, columns=['预测为0的概率', '预测为1的概率'])], axis=1)\n",
    "result1 = result[(result['预测为1的概率'] >= 0.9)&(result['age'] >= 20)&(result['age'] <=50) ]\n",
    "result1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
