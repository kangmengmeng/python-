{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, FloatType\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.7\"\n",
    "spark = SparkSession.builder.\\\n",
    "        config('spark.executor.memory', '6g').\\\n",
    "        config('spark.executor.cores', '8').\\\n",
    "        config('spark.driver.memory','6g').\\\n",
    "        config('spark.executor.instances', '30').\\\n",
    "        appName('test10').\\\n",
    "        enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPos1= spark.sql('select distinct t1.user_guid,t2.is_ride_card, t2.consume_card_cnt,t2.ev_consume_card_cnt,t2.purchase_cnt, \\\n",
    "                         t2.ev_all_total_cnt,t2.total_card_money,t2.total_cnt \\\n",
    "                         from ods.t_driver_approve t1 inner join bikedw.t_dw_bike_user_label t2  on t1.user_guid=t2.user_guid  \\\n",
    "                  where t1.pt=\"20190630\" and t1.approve_status=1 and substr(t1.create_time,1,10) between \"2019-06-01\" and \"2019-06-30\"\\\n",
    "                  and t2.pt=\"20190601\"  and t2.last_ride_time <= 30 and t2.last_ride_time>0 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainPos1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPos1.createOrReplaceTempView(\"trainPos1\")\n",
    "trainPos2= spark.sql('select t1.user_guid,t3.age,t1.is_ride_card, t1.consume_card_cnt,t1.ev_consume_card_cnt,t1.purchase_cnt,t1.ev_all_total_cnt,\\\n",
    "                      t1.total_card_money,t1.total_cnt, t2.sum_cal, t2.sum_ride_time, t2.sum_ride_number, t2.sum_credit_score \\\n",
    "                      from trainPos1 t1  join ods.t_bike_user t2  join dw.dw_user_mid_ds t3\\\n",
    "                      on t1.user_guid=t2.guid  where t2.pt=\"20190601\"  \\\n",
    "                      and t1.user_guid=t3.user_guid and t3.pt=\"20190601\" and t3.sex=0 and t3.age between 18 and 70 ') \n",
    "# trainPos2s=trainPos2.toPandas()\n",
    "# print(trainPos2s.shape)  # (56051, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_train = spark.sql('select userguid as user_guid,count(1) as click from ods.t_bike_yukon_pro_pageview \\\n",
    "     where pt >\"20190501\" and pt<\"20190531\" and (pageid=\"APP_首页_顺风车\" or pageid=\"Alipay_首页_顺风车\" or pageid=\"APP_顺风车_首页\" \\\n",
    "     or pageid=\"APP_顺风车_车主_首页\" or pageid=\"Alipay_顺风车_车主_首页\")  group by userguid') \n",
    "# click_train.createOrReplaceTempView(\"click_train\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPos=trainPos2.join(click_train,'user_guid','left')  # (56051, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPos.createOrReplaceTempView(\"trainPos\")\n",
    "trainPos=spark.sql('select * , 1 lable from trainPos')  #(56051, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_guid: string, age: bigint, is_ride_card: bigint, consume_card_cnt: bigint, ev_consume_card_cnt: bigint, purchase_cnt: bigint, ev_all_total_cnt: bigint, total_card_money: decimal(13,5), total_cnt: bigint, sum_cal: bigint, sum_ride_time: bigint, sum_ride_number: bigint, sum_credit_score: bigint, click: bigint, lable: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainPoss=trainPos.toPandas()\n",
    "# print(trainPoss.shape)  # (56051, 13)\n",
    "# trainPos.shape\n",
    "trainPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNeg1= spark.sql('select t1.user_guid,t1.is_ride_card, t1.consume_card_cnt,t1.ev_consume_card_cnt,t1.purchase_cnt, \\\n",
    "                    t1.ev_all_total_cnt,t1.total_card_money,t1.total_cnt from (select  *  from bikedw.t_dw_bike_user_label \\\n",
    "                     where pt=\"20190601\" and last_ride_time <= 30 and last_ride_time>0 ) t1 left join  \\\n",
    " (select distinct user_guid  ,1 s from ods.t_driver_approve where substr(create_time,1,10)<=\"2019-06-30\" and pt=\"20190630\") t2  \\\n",
    "   on t1.user_guid=t2.user_guid  where s is null limit 2000000 ')  #--34819269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNeg1.createOrReplaceTempView(\"trainNeg1\")\n",
    "trainNeg2= spark.sql('select distinct t1.user_guid,t3.age,t1.is_ride_card, t1.consume_card_cnt,t1.ev_consume_card_cnt,t1.purchase_cnt, \\\n",
    "                    t1.ev_all_total_cnt,t1.total_card_money,t1.total_cnt,t2.sum_cal,t2.sum_ride_time,t2.sum_ride_number,t2.sum_credit_score \\\n",
    "                    from  trainNeg1 t1 join ods.t_bike_user t2 join dw.dw_user_mid_ds t3\\\n",
    "                     on t1.user_guid=t2.guid  where t2.pt=\"20190601\"  \\\n",
    "                     and t1.user_guid=t3.user_guid and t3.pt=\"20190601\" and t3.sex=0 and t3.age between 18 and 70 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNeg=trainNeg2.join(click_train,'user_guid','left')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainNeg.createOrReplaceTempView(\"trainNeg\")\n",
    "trainNeg=spark.sql('select * , 0  lable from trainNeg ')  #  负样本抽取 1000000  正样本 56051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_guid: string, age: bigint, is_ride_card: bigint, consume_card_cnt: bigint, ev_consume_card_cnt: bigint, purchase_cnt: bigint, ev_all_total_cnt: bigint, total_card_money: decimal(13,5), total_cnt: bigint, sum_cal: bigint, sum_ride_time: bigint, sum_ride_number: bigint, sum_credit_score: bigint, click: bigint, lable: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainNegs=trainNeg.toPandas()\n",
    "# print(trainNegs.shape)\n",
    "trainNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNeg.createOrReplaceTempView(\"trainNeg\")\n",
    "trainPos.createOrReplaceTempView(\"trainPos\")\n",
    "train_data=spark.sql('select * from trainNeg union select * from trainPos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_guid: string, age: bigint, is_ride_card: bigint, consume_card_cnt: bigint, ev_consume_card_cnt: bigint, purchase_cnt: bigint, ev_all_total_cnt: bigint, total_card_money: decimal(13,5), total_cnt: bigint, sum_cal: bigint, sum_ride_time: bigint, sum_ride_number: bigint, sum_credit_score: bigint, click: bigint, lable: int]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# traindatas=traindata.toPandas()\n",
    "# print(traindatas.shape)  # (1095771, 14)   5万：100万  1：20\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPos1= spark.sql('select distinct t1.user_guid,t2.is_ride_card, t2.consume_card_cnt,t2.ev_consume_card_cnt,t2.purchase_cnt, \\\n",
    "                         t2.ev_all_total_cnt,t2.total_card_money,t2.total_cnt \\\n",
    "                         from ods.t_driver_approve t1 inner join bikedw.t_dw_bike_user_label t2  on t1.user_guid=t2.user_guid  \\\n",
    "                  where t1.pt=\"20190731\" and t1.approve_status=1 and substr(t1.create_time,1,10) between \"2019-07-01\" and \"2019-07-31\"\\\n",
    "                  and t2.pt=\"20190701\"  and t2.last_ride_time <= 30 and t2.last_ride_time>0 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPos1.createOrReplaceTempView(\"testPos1\")\n",
    "testPos2= spark.sql('select t1.user_guid,t3.age,t1.is_ride_card, t1.consume_card_cnt,t1.ev_consume_card_cnt,t1.purchase_cnt,t1.ev_all_total_cnt,\\\n",
    "                      t1.total_card_money,t1.total_cnt, t2.sum_cal, t2.sum_ride_time, t2.sum_ride_number, t2.sum_credit_score \\\n",
    "                      from testPos1 t1  join ods.t_bike_user t2  join dw.dw_user_mid_ds t3\\\n",
    "                      on t1.user_guid=t2.guid  where t2.pt=\"20190701\"  \\\n",
    "                      and t1.user_guid=t3.user_guid and t3.pt=\"20190701\" and t3.sex=0 and t3.age between 18 and 70 ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_test = spark.sql('select userguid as user_guid,count(1) as click from ods.t_bike_yukon_pro_pageview \\\n",
    "     where pt >\"20190601\" and pt<\"20190630\" and (pageid=\"APP_首页_顺风车\" or pageid=\"Alipay_首页_顺风车\" or pageid=\"APP_顺风车_首页\" \\\n",
    "     or pageid=\"APP_顺风车_车主_首页\" or pageid=\"Alipay_顺风车_车主_首页\")  group by userguid') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPos=testPos2.join(click_test,'user_guid','left')  # (56051, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPos.createOrReplaceTempView(\"testPos\")\n",
    "testPos=spark.sql('select * , 1 lable from testPos')  #(56051, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNeg1= spark.sql('select t1.user_guid,t1.is_ride_card, t1.consume_card_cnt,t1.ev_consume_card_cnt,t1.purchase_cnt, \\\n",
    "                    t1.ev_all_total_cnt,t1.total_card_money,t1.total_cnt from (select  *  from bikedw.t_dw_bike_user_label \\\n",
    "                     where pt=\"20190701\" and last_ride_time <= 30 and last_ride_time>0 ) t1 left join  \\\n",
    " (select distinct user_guid  ,1 s from ods.t_driver_approve where substr(create_time,1,10)<=\"2019-07-31\" and pt=\"20190731\") t2  \\\n",
    "   on t1.user_guid=t2.user_guid  where s is null limit 10000000 ')  #--34819269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNeg1.createOrReplaceTempView(\"testNeg1\")\n",
    "testNeg2= spark.sql('select distinct t1.user_guid,t3.age,t1.is_ride_card, t1.consume_card_cnt,t1.ev_consume_card_cnt,t1.purchase_cnt, \\\n",
    "                    t1.ev_all_total_cnt,t1.total_card_money,t1.total_cnt,t2.sum_cal,t2.sum_ride_time,t2.sum_ride_number,t2.sum_credit_score \\\n",
    "                    from  testNeg1 t1 join ods.t_bike_user t2 join dw.dw_user_mid_ds t3\\\n",
    "                     on t1.user_guid=t2.guid  where t2.pt=\"20190701\"  \\\n",
    "                     and t1.user_guid=t3.user_guid and t3.pt=\"20190701\" and t3.sex=0 and t3.age between 18 and 70 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNeg=testNeg2.join(click_test,'user_guid','left')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNeg.createOrReplaceTempView(\"testNeg\")\n",
    "testNeg=spark.sql('select * , 0  lable from testNeg')  #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNeg.createOrReplaceTempView(\"testNeg\")\n",
    "testPos.createOrReplaceTempView(\"testPos\")\n",
    "test_data=spark.sql('select * from testNeg union select * from testPos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_guid: string, age: bigint, is_ride_card: bigint, consume_card_cnt: bigint, ev_consume_card_cnt: bigint, purchase_cnt: bigint, ev_all_total_cnt: bigint, total_card_money: decimal(13,5), total_cnt: bigint, sum_cal: bigint, sum_ride_time: bigint, sum_ride_number: bigint, sum_credit_score: bigint, click: bigint, lable: int]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdatas=testdata.toPandas()    \n",
    "# print(testdatas.shape)  #       5 万：500万  1:100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape (1095859, 15)\n",
      "train save over\n",
      "test_data.shape (5354065, 15)\n",
      "test save over\n"
     ]
    }
   ],
   "source": [
    "def age(x):\n",
    "    if   18 <= x < 25:    y = 0\n",
    "    elif 25 <= x < 35:    y = 1\n",
    "    elif 35 <= x < 45:    y = 2\n",
    "    elif 45 <= x < 55:    y = 3\n",
    "    elif 55 <= x < 65:    y = 4\n",
    "    else:  y = 5\n",
    "    return y\n",
    "\n",
    "def cal(x):\n",
    "    if   0 <= x < 500:          y = 0\n",
    "    elif 500 <= x < 2000:       y = 1\n",
    "    elif 2000 <= x < 5000:      y = 2\n",
    "    elif 5000 <= x < 20000:     y = 3\n",
    "    elif 20000 <= x < 50000:    y = 4\n",
    "    else:y = 5\n",
    "    return y\n",
    "\n",
    "def sum_ride_time(x):\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 100:        y = 1\n",
    "    elif 100 <= x < 400:     y = 2\n",
    "    elif 400 <= x < 600:     y = 3\n",
    "    elif 600 <= x < 1000:    y = 4\n",
    "    else:y = 5\n",
    "    return y\n",
    "\n",
    "def sum_ride_number(x):\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 10:        y = 1\n",
    "    elif 10 <= x < 50:     y = 2\n",
    "    elif 50 <= x < 100:     y = 3\n",
    "    else:y = 4\n",
    "    return y\n",
    "\n",
    "def sum_credit_score(x): #信用积分\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 120:        y = 1\n",
    "    elif 120 <= x < 300:     y = 2\n",
    "    else:y = 3\n",
    "    return y\n",
    "def consume_card_cnt(x): #已消费的单车骑行券数量\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 3:          y = 1\n",
    "    elif 3 <= x <= 5:        y = 2\n",
    "    else:y = 3\n",
    "    return y\n",
    "def ev_consume_card_cnt(x): #已消费的助力车骑行券数量\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 3:          y = 1\n",
    "    else:y = 2\n",
    "    return y\n",
    "def purchase_cnt(x): #购卡次数\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 3:          y = 1\n",
    "    else:y = 2\n",
    "    return y\n",
    "def ev_all_total_cnt(x): #助力车骑行总次数\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 5:          y = 1\n",
    "    else:y = 2\n",
    "    return y\n",
    "def total_card_money(x): #购卡总金额\n",
    "    if   x == 0:            y = 0\n",
    "    elif 0 < x < 10:        y = 1\n",
    "    elif 10 <= x < 30:      y = 2\n",
    "    elif 30 <= x < 50:      y = 3\n",
    "    else:y = 4\n",
    "    return y\n",
    "def total_cnt(x): #打车总次数\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x < 5:          y = 1\n",
    "    else:y = 2\n",
    "    return y\n",
    "def click (x): # 顺风车页面点击次数\n",
    "    if   x == 0:             y = 0\n",
    "    elif 0 < x <= 10:        y = 1\n",
    "    elif 10 < x <= 50:       y = 2\n",
    "    elif 50 < x <= 100:      y = 3\n",
    "    else:y = 4\n",
    "    return y\n",
    "\n",
    "train_data = train_data.toPandas()\n",
    "print(\"train_data.shape\",train_data.shape)\n",
    "col1, row = train_data.shape\n",
    "train_data_x = []\n",
    "train_data_y = []\n",
    "\n",
    "for i in range(col1):\n",
    "    train_data_one = []\n",
    "    train_data_one.append(age(train_data[\"age\"][i]))\n",
    "    train_data_one.append(cal(train_data[\"sum_cal\"][i]))\n",
    "    train_data_one.append(sum_ride_time(train_data[\"sum_ride_time\"][i]))\n",
    "    train_data_one.append(sum_ride_number(train_data[\"sum_ride_number\"][i]))\n",
    "    train_data_one.append(sum_credit_score(train_data[\"sum_credit_score\"][i]))\n",
    "    train_data_one.append(train_data[\"is_ride_card\"][i])\n",
    "    train_data_one.append(train_data[\"consume_card_cnt\"][i])\n",
    "    train_data_one.append(train_data[\"ev_consume_card_cnt\"][i])\n",
    "    train_data_one.append(train_data[\"purchase_cnt\"][i])\n",
    "    train_data_one.append(ev_all_total_cnt(train_data[\"ev_all_total_cnt\"][i]))\n",
    "    train_data_one.append(total_card_money(train_data[\"total_card_money\"][i]))\n",
    "    train_data_one.append(train_data[\"total_cnt\"][i])\n",
    "    train_data_one.append(click(train_data[\"click\"][i]))\n",
    "    train_data_y.append(train_data[\"lable\"][i])\n",
    "    train_data_x.append(train_data_one)\n",
    "    \n",
    "print(\"train save over\")\n",
    "\n",
    "test_data = test_data.toPandas()\n",
    "print(\"test_data.shape\",test_data.shape)\n",
    "col2, row = test_data.shape\n",
    "test_data_x = []\n",
    "test_data_y = []\n",
    "\n",
    "for i in range(col2):\n",
    "    test_data_one = []\n",
    "    test_data_one.append(age(test_data[\"age\"][i]))\n",
    "    test_data_one.append(cal(test_data[\"sum_cal\"][i]))\n",
    "    test_data_one.append(sum_ride_time(test_data[\"sum_ride_time\"][i]))\n",
    "    test_data_one.append(sum_ride_number(test_data[\"sum_ride_number\"][i]))\n",
    "    test_data_one.append(sum_credit_score(test_data[\"sum_credit_score\"][i]))\n",
    "    test_data_one.append(test_data[\"is_ride_card\"][i])\n",
    "    test_data_one.append(test_data[\"consume_card_cnt\"][i])\n",
    "    test_data_one.append(test_data[\"ev_consume_card_cnt\"][i])\n",
    "    test_data_one.append(test_data[\"purchase_cnt\"][i])\n",
    "    test_data_one.append(ev_all_total_cnt(test_data[\"ev_all_total_cnt\"][i]))\n",
    "    test_data_one.append(total_card_money(test_data[\"total_card_money\"][i]))\n",
    "    test_data_one.append(test_data[\"total_cnt\"][i])\n",
    "    test_data_one.append(click(test_data[\"click\"][i]))\n",
    "    test_data_y.append(test_data[\"lable\"][i])\n",
    "    test_data_x.append(test_data_one)\n",
    "\n",
    "print(\"test save over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095859, 13)\n",
      "(5354065, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train1_data = pd.DataFrame(train_data_x, columns=['age', 'sum_cal', 'sum_ride_time', 'sum_ride_number', 'sum_credit_score',\n",
    "                                           'is_ride_card', 'consume_card_cnt', 'ev_consume_card_cnt', 'purchase_cnt',\n",
    "                                           'ev_all_total_cnt', 'total_card_money', 'total_cnt', 'click'])\n",
    "test1_data = pd.DataFrame(test_data_x, columns=['age', 'sum_cal', 'sum_ride_time', 'sum_ride_number', 'sum_credit_score',\n",
    "                                           'is_ride_card', 'consume_card_cnt', 'ev_consume_card_cnt', 'purchase_cnt',\n",
    "                                           'ev_all_total_cnt', 'total_card_money', 'total_cnt', 'click'])\n",
    "\n",
    "print(train1_data.shape)\n",
    "print(test1_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2 save over\n",
      "train2 save over\n"
     ]
    }
   ],
   "source": [
    "age = pd.get_dummies(test1_data[\"age\"], prefix='age')\n",
    "cal = pd.get_dummies(test1_data[\"sum_cal\"], prefix='cal')\n",
    "test2 = age.join(cal)\n",
    "ride_time = pd.get_dummies(test1_data[\"sum_ride_time\"], prefix=\"ride_time\")\n",
    "test2 = test2.join(ride_time)\n",
    "ride_number = pd.get_dummies(test1_data[\"sum_ride_number\"], prefix=\"sum_ride_number\")\n",
    "test2 = test2.join(ride_number)\n",
    "credit_score = pd.get_dummies(test1_data[\"sum_credit_score\"], prefix=\"sum_credit_score\")\n",
    "test2 = test2.join(credit_score)\n",
    "test2 = test2.join(test1_data[\"is_ride_card\"])\n",
    "test2 = test2.join(test1_data[\"consume_card_cnt\"])\n",
    "test2 = test2.join(test1_data[\"ev_consume_card_cnt\"])\n",
    "test2 = test2.join(test1_data[\"purchase_cnt\"])\n",
    "ev_cnt = pd.get_dummies(test1_data[\"ev_all_total_cnt\"], prefix=\"ev_cnt\")\n",
    "test2 = test2.join(ev_cnt)\n",
    "card_money = pd.get_dummies(test1_data[\"total_card_money\"], prefix=\"card_money\")\n",
    "test2 = test2.join(card_money)\n",
    "test2 = test2.join(test1_data[\"total_cnt\"])\n",
    "click = pd.get_dummies(test1_data[\"click\"], prefix=\"click\")\n",
    "test2 = test2.join(click)\n",
    "test2 = pd.DataFrame(test2, index=None, columns=None)\n",
    "print(\"test2 save over\")\n",
    "\n",
    "age = pd.get_dummies(train1_data[\"age\"], prefix='age')\n",
    "cal = pd.get_dummies(train1_data[\"sum_cal\"], prefix='cal')\n",
    "train2 = age.join(cal)\n",
    "ride_time = pd.get_dummies(train1_data[\"sum_ride_time\"], prefix=\"ride_time\")\n",
    "train2 = train2.join(ride_time)\n",
    "ride_number = pd.get_dummies(train1_data[\"sum_ride_number\"], prefix=\"sum_ride_number\")\n",
    "train2 = train2.join(ride_number)\n",
    "credit_score = pd.get_dummies(train1_data[\"sum_credit_score\"], prefix=\"sum_credit_score\")\n",
    "train2 = train2.join(credit_score)\n",
    "train2 = train2.join(train1_data[\"is_ride_card\"])\n",
    "train2 = train2.join(train1_data[\"consume_card_cnt\"])\n",
    "train2 = train2.join(train1_data[\"ev_consume_card_cnt\"])\n",
    "train2 = train2.join(train1_data[\"purchase_cnt\"])\n",
    "ev_cnt = pd.get_dummies(train1_data[\"ev_all_total_cnt\"], prefix=\"ev_cnt\")\n",
    "train2 = train2.join(ev_cnt)\n",
    "card_money = pd.get_dummies(train1_data[\"total_card_money\"], prefix=\"card_money\")\n",
    "train2 = train2.join(card_money)\n",
    "train2 = train2.join(train1_data[\"total_cnt\"])\n",
    "click = pd.get_dummies(train1_data[\"click\"], prefix=\"click\")\n",
    "train2 = train2.join(click)\n",
    "train2 = pd.DataFrame(train2, index=None, columns=None)\n",
    "print(\"train2 save over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------begin---------\n",
      "---------train over---------\n",
      "w:  [[-1.37906046e-01  1.06827538e+00  8.01155604e-01  8.85555323e-02\n",
      "  -7.67326221e-01 -2.11414013e+00 -5.17601372e-02 -4.89748965e-02\n",
      "  -6.82801825e-02 -7.41293790e-02 -2.55041932e-01 -5.63199370e-01\n",
      "  -3.42325209e-01  2.68028415e-03 -5.21959175e-02 -1.38448654e-01\n",
      "  -2.02976304e-01 -3.28120097e-01 -3.38884188e-01 -2.85921546e-01\n",
      "  -1.86186613e-01 -1.60095474e-01 -9.02980748e-02 -5.59189808e-01\n",
      "  -3.74534315e-01 -1.21381817e-01 -6.27993348e-03 -1.37148292e-01\n",
      "   2.71376242e-03 -6.13027163e-03  5.10255698e-02 -4.24432694e-01\n",
      "  -2.92015711e-01 -3.44937467e-01  4.32133147e-02 -4.19469517e-02\n",
      "  -1.05889833e-01 -3.24303629e-01 -6.32458773e-01  2.07956818e-04\n",
      "  -5.78730625e-01  5.81425969e-01  8.04926659e-01 -1.86900788e+00]]\n",
      "b:  [-1.0613859]\n",
      "精确率:0.0006397811507236145\n",
      "准确率:0.9914847877267086\n",
      "召回率:0.09034267912772585\n",
      "f1:0.0012705645249622116\n",
      "auc:0.7286229715599447\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one label specified must be in y_true",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0dc8c3ec2db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-0dc8c3ec2db3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     res_3 = pd.concat(\n\u001b[1;32m     45\u001b[0m         [pd.DataFrame(target, columns=['label']), pd.DataFrame(precision, columns=['预测结果']), pd.DataFrame(pro, columns=['预测为0的概率', '预测为1的概率'])], axis=1)\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-0dc8c3ec2db3>\u001b[0m in \u001b[0;36msta\u001b[0;34m(res_0, a, b)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mq1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'预测为1的概率'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'预测为1的概率'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmat_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'预测结果'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     new = pd.DataFrame(mat_0.reshape(1, 4), columns=['预测转化_实际转化', '预测未转化_实际转化', '预测转化_实际未转化', '预测未转化_实际未转化'],\n",
      "\u001b[0;32m/data1/app/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one label specified must be in y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least one label specified must be in y_true"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import metrics\n",
    "from xgboost import plot_importance\n",
    "\n",
    "\n",
    "def sta(res_0, a, b):\n",
    "    q1 = res_0[(res_0['预测为1的概率'] >= a) & (res_0['预测为1的概率'] < b)]\n",
    "    mat_0 = confusion_matrix(q1['label'], q1['预测结果'], labels=[1, 0])\n",
    "\n",
    "    new = pd.DataFrame(mat_0.reshape(1, 4), columns=['预测转化_实际转化', '预测未转化_实际转化', '预测转化_实际未转化', '预测未转化_实际未转化'],\n",
    "                       index=['预测概率{0}-{1}'.format(a, b)])\n",
    "    new['准确率'] = metrics.accuracy_score(q1['label'], q1['预测结果'])\n",
    "    metrics.accuracy_score(q1['label'], q1['预测结果'])\n",
    "    return new\n",
    "\n",
    "def main():\n",
    "   \n",
    "    print(\"---------begin---------\")\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train2, train_data_y)\n",
    "\n",
    "    print(\"---------train over---------\")\n",
    "    print(\"w: \", model.coef_)\n",
    "#     w = model.coef_\n",
    "#     save = pd.DataFrame(w)\n",
    "#     save.to_csv(r'D:\\work\\司机挖掘\\w.csv', index=False, header=False)\n",
    "    print(\"b: \", model.intercept_)\n",
    "    precision = model.predict(test2)    \n",
    "    target = np.array(test_data_y)\n",
    "    print('精确率:{}'.format(precision_score(precision, target)))\n",
    "    print('准确率:{}'.format(accuracy_score(precision, target)))\n",
    "    print('召回率:{}'.format(recall_score(precision, target)))\n",
    "    print('f1:{}'.format(f1_score(precision, target)))\n",
    "    pro = model.predict_proba(test2)  \n",
    "    print('auc:{}'.format(roc_auc_score(target, pro[:, 1])))\n",
    "\n",
    "\n",
    "    res_3 = pd.concat(\n",
    "        [pd.DataFrame(target, columns=['label']), pd.DataFrame(precision, columns=['预测结果']), pd.DataFrame(pro, columns=['预测为0的概率', '预测为1的概率'])], axis=1)\n",
    "    df3 = sta(res_3, 0.9, 1)\n",
    "    for a, b in [[0.8, 0.9], [0.7, 0.8], [0.6, 0.7], [0.5, 0.6], [0.4, 0.5], [0.3, 0.4], [0.2, 0.3], [0.1, 0.2], [0, 0.1]]:\n",
    "        df_new = pd.concat([df3, sta(res_3, a, b)])\n",
    "        df3 = df_new\n",
    "    print(df_new)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
